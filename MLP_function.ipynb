{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xdata', 'ydata']\n",
      "['xdata', 'ydata']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "filename = 'mnist_traindata.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "a_group_key = list(f.keys())\n",
    "print(a_group_key)\n",
    "xdata = np.array(f[a_group_key[0]])\n",
    "ydata = np.array(f[a_group_key[1]])\n",
    "\n",
    "filename1 = 'mnist_testdata.hdf5'\n",
    "f1 = h5py.File(filename1, 'r')\n",
    "b_group_key = list(f1.keys())\n",
    "print(b_group_key)\n",
    "xdata_test = np.array(f1[b_group_key[0]])\n",
    "ydata_test = np.array(f1[b_group_key[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(xdata_test.shape)\n",
    "print(ydata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_train, xdata_val, ydata_train, ydata_val = train_test_split(xdata,ydata,test_size = 0.16666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print((ydata_train))\n",
    "# print(ydata_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "def drelu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def dtanh(x):\n",
    "    return (1-(np.tanh(x)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train :   92.018 .....   Accuracy for val :   90.71000000000001\n",
      "Accuracy for train :   94.306 .....   Accuracy for val :   92.38\n",
      "Accuracy for train :   95.492 .....   Accuracy for val :   93.08999999999999\n",
      "Accuracy for train :   96.28999999999999 .....   Accuracy for val :   93.65\n",
      "Accuracy for train :   96.64399999999999 .....   Accuracy for val :   93.83\n",
      "Accuracy for train :   96.898 .....   Accuracy for val :   94.06\n",
      "Accuracy for train :   97.25 .....   Accuracy for val :   94.26\n",
      "Accuracy for train :   97.502 .....   Accuracy for val :   94.36\n",
      "Accuracy for train :   97.76 .....   Accuracy for val :   94.44\n",
      "Accuracy for train :   97.95 .....   Accuracy for val :   94.57\n",
      "Accuracy for train :   98.10600000000001 .....   Accuracy for val :   94.42\n",
      "Accuracy for train :   98.26 .....   Accuracy for val :   94.51\n",
      "Accuracy for train :   98.406 .....   Accuracy for val :   94.59\n",
      "Accuracy for train :   98.542 .....   Accuracy for val :   94.63000000000001\n",
      "Accuracy for train :   98.70400000000001 .....   Accuracy for val :   94.56\n",
      "Accuracy for train :   98.834 .....   Accuracy for val :   94.5\n",
      "Accuracy for train :   98.968 .....   Accuracy for val :   94.43\n",
      "Accuracy for train :   99.07000000000001 .....   Accuracy for val :   94.47\n",
      "Accuracy for train :   99.19 .....   Accuracy for val :   94.5\n",
      "Accuracy for train :   99.32 .....   Accuracy for val :   94.61\n",
      "Accuracy for train :   99.466 .....   Accuracy for val :   94.74000000000001\n",
      "Accuracy for train :   99.55000000000001 .....   Accuracy for val :   94.83\n",
      "Accuracy for train :   99.626 .....   Accuracy for val :   94.91000000000001\n",
      "Accuracy for train :   99.684 .....   Accuracy for val :   95.02000000000001\n",
      "Accuracy for train :   99.75 .....   Accuracy for val :   95.06\n",
      "Accuracy for train :   99.786 .....   Accuracy for val :   95.05\n",
      "Accuracy for train :   99.816 .....   Accuracy for val :   95.06\n",
      "Accuracy for train :   99.854 .....   Accuracy for val :   95.05\n",
      "Accuracy for train :   99.87 .....   Accuracy for val :   95.04\n",
      "Accuracy for train :   99.888 .....   Accuracy for val :   95.07\n",
      "Accuracy for train :   99.898 .....   Accuracy for val :   95.08\n",
      "Accuracy for train :   99.908 .....   Accuracy for val :   95.07\n",
      "Accuracy for train :   99.92 .....   Accuracy for val :   95.12\n",
      "Accuracy for train :   99.942 .....   Accuracy for val :   95.1\n",
      "Accuracy for train :   99.95 .....   Accuracy for val :   95.1\n",
      "Accuracy for train :   99.956 .....   Accuracy for val :   95.1\n",
      "Accuracy for train :   99.96000000000001 .....   Accuracy for val :   95.08\n",
      "Accuracy for train :   99.964 .....   Accuracy for val :   95.06\n",
      "Accuracy for train :   99.97200000000001 .....   Accuracy for val :   95.06\n",
      "Accuracy for train :   99.98 .....   Accuracy for val :   95.07\n",
      "Accuracy for train :   99.982 .....   Accuracy for val :   95.08\n",
      "Accuracy for train :   99.982 .....   Accuracy for val :   95.08\n",
      "Accuracy for train :   99.984 .....   Accuracy for val :   95.05\n",
      "Accuracy for train :   99.98599999999999 .....   Accuracy for val :   95.05\n",
      "Accuracy for train :   99.99 .....   Accuracy for val :   95.02000000000001\n",
      "Accuracy for train :   99.992 .....   Accuracy for val :   95.04\n",
      "Accuracy for train :   99.992 .....   Accuracy for val :   95.02000000000001\n",
      "Accuracy for train :   99.992 .....   Accuracy for val :   95.02000000000001\n",
      "Accuracy for train :   99.994 .....   Accuracy for val :   95.02000000000001\n",
      "Accuracy for train :   99.994 .....   Accuracy for val :   94.99\n"
     ]
    }
   ],
   "source": [
    "# 1 hidden layer\n",
    "\n",
    "import numpy as np\n",
    "nn_input_dim = 784\n",
    "nn_hdim = 100\n",
    "nn_output_dim = 10\n",
    "epsilon = 0.7\n",
    "num_epochs = 50\n",
    "mini_batch = 50\n",
    "accuracy_val = []\n",
    "accuracy_train = []\n",
    "\n",
    "w1_avg = 0\n",
    "b1_avg = 0\n",
    "w2_avg = 0\n",
    "b2_avg = 0\n",
    "\n",
    "w1 = np.random.uniform(-1,1,(nn_input_dim,nn_hdim))\n",
    "b1 = np.random.uniform(-1,1,(1, nn_hdim))\n",
    "w2 = np.random.uniform(-1,1,(nn_hdim,nn_output_dim))\n",
    "b2 = np.random.uniform(-1,1,(1, nn_output_dim))\n",
    "\n",
    "y = np.zeros((len(xdata_train),10))\n",
    "y1 = np.zeros((len(xdata_val),10))\n",
    "y2 = np.zeros((len(xdata_train),10))\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    correct_val = 0\n",
    "    correct_train = 0\n",
    "    \n",
    "    ## For training samples\n",
    "    for i in range(0, len(xdata_train)):\n",
    "        ## Forward propogation\n",
    "        a0 = xdata_train[i]\n",
    "        a0 = a0.reshape((1,len(a0)))\n",
    "        z1 = np.dot(a0,w1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = np.dot(a1,w2) + b2\n",
    "        y[i] = softmax(z2)\n",
    "\n",
    "        ## Back propogation\n",
    "        delta3 = y[i] - ydata_train[i]\n",
    "        delta3 = delta3.reshape((1,len(delta3)))\n",
    "        dw2 = np.dot(a1.transpose(), delta3)\n",
    "        db2 = delta3\n",
    "        delta2 = (1-(np.tanh(z1)**2)) * (np.dot(delta3, w2.transpose()))\n",
    "        dw1 = np.dot(a0.transpose(),delta2)\n",
    "        db1 = delta2\n",
    "\n",
    "        ## Adding update to running average\n",
    "        w1_avg += epsilon * dw1\n",
    "        b1_avg += epsilon * db1\n",
    "        w2_avg += epsilon * dw2\n",
    "        b2_avg += epsilon * db2\n",
    "\n",
    "        ## update\n",
    "        if i % mini_batch == 0:\n",
    "            w1 = w1 - (w1_avg / mini_batch)\n",
    "            b1 = b1 - (b1_avg / mini_batch)\n",
    "            w2 = w2 - (w2_avg / mini_batch)\n",
    "            b2 = b2 - (b2_avg / mini_batch)\n",
    "            w1_avg = 0\n",
    "            b1_avg = 0\n",
    "            w2_avg = 0\n",
    "            b2_avg = 0\n",
    "\n",
    "    ## For validation samples\n",
    "    for j in range(0, len(xdata_val)):\n",
    "        ## Forward propogation\n",
    "        a0 = xdata_val[j]\n",
    "        a0 = a0.reshape((1,len(a0)))\n",
    "        z1 = np.dot(a0,w1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = np.dot(a1,w2) + b2\n",
    "        y1[j] = softmax(z2)\n",
    "\n",
    "        idx_predict = np.argmax(y1[j])\n",
    "        idx_actual = np.argmax(ydata_val[j])\n",
    "        if idx_predict == idx_actual:\n",
    "            correct_val += 1\n",
    "    acc_val = (correct_val/len(xdata_val)) * 100\n",
    "    accuracy_val.append(acc_val)\n",
    "    \n",
    "    for k in range(0, len(xdata_train)):\n",
    "        ## Forward propogation\n",
    "        a0 = xdata_train[k]\n",
    "        a0 = a0.reshape((1,len(a0)))\n",
    "        z1 = np.dot(a0,w1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = np.dot(a1,w2) + b2\n",
    "        y2[k] = softmax(z2)\n",
    "\n",
    "        idx_predict = np.argmax(y2[k])\n",
    "        idx_actual = np.argmax(ydata_train[k])\n",
    "        if idx_predict == idx_actual:\n",
    "            correct_train += 1\n",
    "    acc_train = (correct_train/len(xdata_train)) * 100\n",
    "    accuracy_train.append(acc_train)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('Accuracy for train :  ', acc_train, '.....   Accuracy for val :  ',acc_val )\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VPW9//HXJ5OdEEgCgbCEsAgiIFtEcMPqbV3rQq21VavWllqtVe+vvfW2/m7b23qr/Xlva2+tVa/7xapV0W7aWhGsqCiLFAQRZUvYErKRlSQz398fZwgBJhAgM2cy834+zGPmnJk553NiOJ/57uacQ0RE5EApfgcgIiLxSQlCREQiUoIQEZGIlCBERCQiJQgREYlICUJERCJSghARkYiUIEREJCIlCBERiSjV7wCOxYABA1xJSYnfYYiI9CrLli3b5ZwbeLj39eoEUVJSwtKlS/0OQ0SkVzGzzd15n6qYREQkIiUIERGJSAlCREQi6tVtEJG0tbVRXl5OS0uL36H0WpmZmQwbNoy0tDS/QxERH0UtQZjZI8CFQIVzbmJ4Xz7wDFACbAIud87VmJkB9wLnA03Atc655Udz3vLycvr27UtJSQneYeVIOOeoqqqivLyckSNH+h2OiPgomlVMjwHnHrDvduA159xxwGvhbYDzgOPCP3OB+4/2pC0tLRQUFCg5HCUzo6CgQCUwEYlegnDOvQFUH7D7YuDx8PPHgUs67X/Ced4B+ptZ0dGeW8nh2Oj3JyIQ+zaIQc657QDOue1mVhjePxQo6/S+8vC+7TGOT0TiiHOO9pCjtT3k/QS9xz3h7bZgiJBzhJz33s6PEY+HI/xfx+dCztvReds5h3N0bAdDnX7CMYVC7oBz7/vMEV8n4c+G3H6xcYgloc8eP4jJw/sf+cmOQLw0Ukf6yhrxN2Nmc/GqoSguLo5mTCJJyTlHc1uQ6sZWapvaqGlqpbqxlfqW9o4bs3ezDnY8bws52oMh2oKOtmCI9qCjPRSiPXTAzTV8gz1oX8i76bYHvSSwp1NCOMQ9MuEdqjBfmJuZcAlip5kVhUsPRUBFeH85MLzT+4YB2yIdwDn3IPAgQGlpadz96dTW1vLUU09x4403HtHnzj//fJ566in694/u/3BJDO3BEPUt7dS3tLO7pY3dLW3saQvR0hakpT3Y6Xn4sS3EnvbwY/g9za1Bmtv2PTa1BmlpC7K7pZ3W9tBhYwikGOmBFNICRnpqCmmBFFIDRlrKvuepKUZKSvjRjIy0FFLMCHTalxowAikpBAxSAymkp6aQHkghI3Xf8/TUTj/h7YzwOVPCx0kxMLxHws8jMWPf+806ti18TRB+PWX//akpKaSk0PEYCF+HdTrW3hiOppY2pVMse4/nt1gniN8D1wB3hR9f6rT/m2b2NHAyULe3Kqq3qa2t5de//vVBCSIYDBIIBLr83J///OdohyZxyjlHTVMbW6qbKKtuoqymiaqGVhpa2mnY0079nnYaWtq85y3t7G5uo7E1eETnSAsYmakBMtICZKalkJkWICv80z87nSHp4e30ADkZqeT1SScvO43+2enkZaeT3yeNvplpZKSmkJEaID01peNmKokrmt1cfwucCQwws3LgB3iJ4Vkzux7YAnw+/PY/43Vx/Rivm+t1PRHDj/7wAWu27e6JQ3U4YUguP/jshC5fv/322/nkk0+YMmUKaWlp5OTkUFRUxPvvv8+aNWu45JJLKCsro6WlhVtuuYW5c+cC++aVamho4LzzzuO0007jrbfeYujQobz00ktkZWVFPN9DDz3Egw8+SGtrK2PGjOHJJ58kOzubnTt3csMNN7BhwwYA7r//fk455RSeeOIJ7rnnHsyME088kSeffLJHfz+yP+cctU1t7Njdws7dLVTs3tPxfOfuFsprmimrbjroht8nPUDfzDRyMlPJyUilb2Yqg3IzyclIJTcrjdzMNHKzUumbmUZuZio5malkpQXIDP9kpKaEn3s3dN3M5WiY68UVfKWlpe7AyfrWrl3L+PHjAX8SxKZNm7jwwgtZvXo1Cxcu5IILLmD16tUdYwqqq6vJz8+nubmZk046iUWLFlFQULBfghgzZgxLly5lypQpXH755Vx00UVcddVVEc9XVVVFQUEBAHfccQeDBg3i5ptv5gtf+AKzZs3i1ltvJRgM0tDQQHl5OXPmzGHx4sUMGDCgI5ZIOv8e5dCcc2ypbmL11t2U1zRRXtNMeU0TW2ubKa9ppinCt/38PukU9s1gWF4Ww/KyGZ6fTXF+NsPzve2cjHhpHpREZGbLnHOlh3tfQv8VHupGHiszZszYb8DZL3/5S+bPnw9AWVkZ69ev77jB7zVy5EimTJkCwPTp09m0aVOXx1+9ejV33HEHtbW1NDQ0cM455wCwYMECnnjiCQACgQD9+vXjiSee4LLLLmPAgAEAXSYHObSWtiCrttaxfHMNyzbXsHxLDbsaWjte75eVxtD+WZQU9OHUMQMY2j+Lon5ZDO6XQWHfTApzM8hI7bq6USReJHSCiAd9+vTpeL5w4UL+9re/8fbbb5Odnc2ZZ54ZcUBaRkZGx/NAIEBzc3OXx7/22mt58cUXmTx5Mo899hgLFy7s8r3Oubho+OpNWttDrNtRz6qtdazaWscH2+pYu303bUGv5F1SkM0ZYwcyfUQek4f1p7ggm9xMTVEiiUEJoof17duX+vr6iK/V1dWRl5dHdnY2H374Ie+8884xn6++vp6ioiLa2tqYN28eQ4cOBeDss8/m/vvv76hiamxs5Oyzz+bSSy/ltttuo6Cg4JBVTMmqtqmVtz+p4q1PqlhRVsO6HfUdySA3M5WJQ/vxldNGMr04j2kj8hiQk3GYI4r0XkoQPaygoIBTTz2ViRMnkpWVxaBBgzpeO/fcc/nNb37DiSeeyLhx45g5c+Yxn+/HP/4xJ598MiNGjGDSpEkdyenee+9l7ty5PPzwwwQCAe6//35mzZrF97//fWbPnk0gEGDq1Kk89thjxxxDb9bU2s67G6t565MqFn+8izXbd+Oc10g8pbg/1582iolDc5k0tB/F+dkqgUlSSehGajl6ifp7dM7xSWUjC9dVsHBdJe9urKY1GCI9kMLU4v6cOmYAp4wuYPLw/qQFNBu+JCY1UouEBUOOv6+vZMGHFby+roKyaq9N57jCHK45ZQSnHzeQk0ryyUpXw7FIZ0oQvcRNN93E4sWL99t3yy23cN11PTJkJCEFQ44/r9rOL19bz/qKBrLSApw6poCvnzGaM8cNZFhett8hisQ1JYhe4r777vM7hF7jwMRwXGEOv/ziVD5zwiAy01RKEOkuJQhJGJESw6++NJXzJxaRopHEIkdMCUJ6vcY97Ty3rJxHFm9kc1WTEoNID1GCkF5re10zj7+1maeWbGZ3SztTi/vz3XOP59wJg5UYRHqAEoT0OivLanl08Ub++I/thJzjvIlF3uC1EXl+hyaSUJQgfJaTk0NDQ4PfYcS95tYgf1i5jSff2cyqrXXkZKRyzSklXHtKCcPz1RtJJBqUICSufVzRwLwlm3l+WTm7W9oZOyiHf794ApdOHUpfzXkkElWJnSBevh12rOrZYw6eBOfd1eXL3/3udxkxYkTHgkE//OEPMTPeeOMNampqaGtr4yc/+QkXX3zxYU/V0NDAxRdfHPFzkdZ16GoNiN6mtqmVl1fv4MUVW1mysZq0gHHuxCKuOrmYGSPzNd2FSIwkdoLwwRVXXMGtt97akSCeffZZXnnlFW677TZyc3PZtWsXM2fO5KKLLjrsjS4zM5P58+cf9Lk1a9Zw55137reuA8C3vvUtZs+ezfz58zvWgOgtmlrbeXXNTv6wchuLPqqkLegYNbAP3zlnHJeXDmdgX02KJxJriZ0gDvFNP1qmTp1KRUUF27Zto7Kykry8PIqKirjtttt44403SElJYevWrezcuZPBgwcf8ljOOb73ve8d9LkFCxZEXNch0hoQ8e4f5bU8ungTr6zeQXNbkMG5mVx36kgumjyECUNyVVoQ8VFiJwifXHbZZTz33HPs2LGDK664gnnz5lFZWcmyZctIS0ujpKQk4joQB+rqc719XQfnHIs+quSBRRt4e0MVfTNSuXTaUC6ePISTSvLVRVUkTmi6yii44oorePrpp3nuuee47LLLqKuro7CwkLS0NF5//XU2b97creN09bmzzz6bZ599lqqqKoCOKqa9a0AABINBdu/u2eVWj1VbMMQLy8s5796/c+2j77FxVyPfO/943vrXs/iPSydx8qgCJQeROKISRBRMmDCB+vp6hg4dSlFREVdeeSWf/exnKS0tZcqUKRx//PHdOk5Xn5swYULEdR26WgPCb3XNbTzz3hYeW7yJbXUtjB2Uwz2fn8xFk4eQnqrvKCLxSutBSEQ98Xssq27ikcUbefa9Mhpbg8wcld8xk2pvriIT6e20HoT4ZtnmGh5+cwOvrN5BihmfnTyE608bycSh8d9oLiL7KEHEgVWrVnH11Vfvty8jI4MlS5b4FNHR+WBbHT/984e8+fEucjNT+frs0Vwzq4TB/TL9Dk1EjkJCJoje1stn0qRJvP/++36H0eFIqx131LVwz1/X8fzycvplpXHHBeP54oxi+mQk5J+XSNJIuH/BmZmZVFVVUVBQ0KuSRLxwzlFVVUVm5uG/9TfsaeeBRZ/w0N83EArB3NNHceOnxtAvS1NgiCSChEsQw4YNo7y8nMrKSr9D6bUyMzMZNmxYl683twZ5dmkZ/73gY3Y17OGiyUP4zjnjNGmeSIJJuASRlpbGyJEj/Q4jIdU2tfLk25t59K1NVDe2MqMkn4e+PJ2pxZpmWyQRJVyCkJ63rbaZh9/cyG/f3UJTa5Czji/khtmjOakkT9V4IglMCUK6tGlXI/e9/jHzV2zFARdNHsLXZ4/i+MG5focmIjGgBCEH2VzVyH8v8BJDaopx1cwRXH/aSLUxiCQZJQjpsLmqkV8t+JgXwonhmlkl3DB7FIW5GscgkoyUIISy6iZ++dp6JQYR2Y8SRBKrrN/Dfa9/zLwlmzFTYhCR/SlBJKHdLW08uGgDjyzeyJ72EJeXDuNbZx9HUb8sv0MTkTjiS4Iws1uArwEGPOSc+4WZTQF+A2QC7cCNzrl3/YgvUbW0BXn8rU38euEn1DW3ceGJRfzzp8cyamCO36GJSByKeYIws4l4yWEG0Aq8YmZ/An4G/Mg597KZnR/ePjPW8SWi9mCI55aV84u/rWfH7hZmjx3Id84Zp9lVReSQ/ChBjAfecc41AZjZIuBSwAF7O9j3A7b5EFtCcc7xyuod/L+/rmNDZSNTi/vziyumMHNUgd+hiUgv4EeCWA3caWYFQDNwPrAUuBX4i5ndg7cU6ik+xJYw3vpkF3e/so6VZbWMKczhgaun85kTBmnks4h0W8wThHNurZndDbwKNAAr8docvgHc5px73swuBx4G/unAz5vZXGAuQHFxcczi7i0qdrfwf19azV8+2ElRv0x+9rkTmTNtKKkBLe0pIkfG9yVHzew/gHLgp0B/55wz72tunXPukHM6RFpyNFk55/jdsnJ+8sc17GkP8a2zj+P600aSmRbwOzQRiTNxveSomRU65yrMrBiYA8wCbgZmAwuBs4D1fsTWG5VVN/G9+av4+/pdzCjJ567PTVLPJBE5Zn6Ng3g+3AbRBtzknKsxs68B95pZKtBCuBpJuhYKOZ54exM/+8s6DPjxJRO5ckYxKSlqZxCRY+dLgnDOnR5h35vAdB/C6ZXqmtu4cd4yFn9cxeyxA/mPOZMY2l8D3USk52gkdS+0rbaZ6x59jw27GrhrziS+cNJw9U4SkR6nBNHLfLhjN9c+8h6Ne9p57LoZnDpmgN8hiUiCUoLoRd76eBdff3IZ2RkBnr1hFuOLtHCPiESPEkQv8dL7W/n271YyckAfHrtuBkPU3iAiUaYEEeecczzwxgbuevlDTh6Zz4NfLqVfVprfYYlIElCCiGPtwRD/9vsPeGrJFi48sYj/vHwyGaka+CYisaEEEaca9rRz07zlLPqokm+cOZrvfGacxjeISEwpQcSh7XXNfOWxpXy0s56fzpnEF2dozikRiT0liDjzwbY6vvLYezTuCfLItScxe+xAv0MSkSSlBBFHXv+wgm8+tZzcrDR+p26sIuIzJYg48fq6Cq5//D3GF+XyyLUnMSg30++QRCTJKUHEgfU76/nWUys4fnAuz3x9FjkZ+t8iIv7TKjI+q2ls5atPLCUjLcBD15QqOYhI3FCC8FFbMMQ35i1je20LD1w9XbOxikhc0ddVnzjn+MHvP+CdDdX81+WTmT4iz++QRET2oxKET558ZzNPLdnCDbNHM2faML/DERE5iBKED95cv4sf/WEN/zS+kO+cM87vcEREIlKCiLGPdtZz47xljBmYwy+umEpA02eISJxSgoihtz+p4rL73yI9NcD/qMeSiMQ5JYgYmb+inC8/soTC3Ezm33gKw/Oz/Q5JROSQ9BU2ypxz/GrBx/znqx8xc1Q+D1xVSr9srecgIvFPCSKK2oIh7pi/mmeWlnHp1KHc9blJWs9BRHoNJYgoqW9p48Z5y/n7+l3cfNYY/vnTYzFTg7SI9B5KEFHQ2h7i+seWsnxLDT/73IlcftJwv0MSETliShA9zDnHv720mnc3VXPvFVO4eMpQv0MSETkq6sXUwx5/axNPv1fGjWeOVnIQkV5NCaIHvbl+Fz/+01r+afwgvv0ZjZAWkd5NCaKHbNzV2GmE9BRSNEJaRHo5JYgesLulja8+/h6BFNMIaRFJGLqTHaNgyHHzUyvYXNXE/371ZI2QFpGEoQRxjO756zoWfVTJnZdOZOaoAr/DERHpMd2qYjKz583sAjNTlVQn9S1tPPLmRi6ZMoQrTx7hdzgiIj2quzf8+4EvAevN7C4zOz6KMfUaL6/awZ72EF8+pcTvUEREely3EoRz7m/OuSuBacAm4FUze8vMrjOzpJ157vnl5Ywc0Iepw/v7HYqISI/rdpWRmRUA1wJfBVYA9+IljFeP9KRmdouZrTazD8zs1k77bzazdeH9PzvS48ZSeU0TSzZWM2fqUM2xJCIJqVuN1Gb2AnA88CTwWefc9vBLz5jZ0iM5oZlNBL4GzABagVfM7E/AMOBi4ETn3B4zKzyS48baiyu2AnDJVI2WFpHE1N1eTL9yzi2I9IJzrvQIzzkeeMc51wRgZouAS4FS4C7n3J7wcSuO8Lgx45zjhRVbmTEyX91aRSRhdbeKabyZdVS0m1memd14lOdcDZxhZgVmlg2cDwwHxgKnm9kSM1tkZidF+rCZzTWzpWa2tLKy8ihDODYry+vYUNnI56ap9CAiiau7CeJrzrnavRvOuRq8aqIj5pxbC9yN13bxCrASaMcrzeQBM4HvAM9ahMp959yDzrlS51zpwIEDjyaEY/bC8nIyUlM4b1KRL+cXEYmF7iaIlM43azMLAOlHe1Ln3MPOuWnOuTOAamA9UA684DzvAiFgwNGeI1pa20P8YeU2Pn3CIHIzk7YDl4gkge62QfwF7xv9bwAH3ID37f+omFmhc67CzIqBOcAsvIRwFrDQzMbiJaBdR3uOaFm4roKapjbmqHpJRBJcdxPEd4GvA98ADPgr8D/HcN7nw91m24CbnHM1ZvYI8IiZrcbr3XSNc84dwzmiYv6KrQzISef04/yp3hIRiZVuJQjnXAhvNPX9PXFS59zpEfa1Alf1xPGjpbapldfWVnDVzBGkBTTriIgktu6OgzgO+ClwApC5d79zblSU4opLf/zHdlqDIVUviUhS6O7X4EfxSg/twKeAJ/AGzSWV+Su2MnZQDhOG5PodiohI1HU3QWQ5514DzDm32Tn3Q7wG5aSxaVcjyzbXMGfaME2tISJJobuN1C3hqb7Xm9k3ga1AXE+F0dPmr9iKGVw8ZYjfoYiIxER3SxC3AtnAt4DpeI3J10QrqHjjnGP+iq2cOnoARf2y/A5HRCQmDluCCA+Ku9w59x2gAbgu6lHFmU8qG9lS3cQ3zhztdygiIjFz2BKEcy4ITI807UWyWLKxCoBZWlJURJJId9sgVgAvmdnvgMa9O51zL0QlqjizZEM1g3IzGFGgmVtFJHl0N0HkA1Xs33PJAQmfIJxzLNlYxYyRBeq9JCJJpbsjqZOu3WGvzVVN7Ny9h5NH5vsdiohITHV3JPWjeCWG/TjnvtLjEcWZve0PM0cpQYhIculuFdMfOz3PxFsBblvPhxN/lmyoZkBOOqMH5vgdiohITHW3iun5zttm9lvgb1GJKM4s2VjNjJH5an+QxBQKQe1mqFgLFWu8xz27ISsPMvt7j1l5kNUfMvriTeZ8BDJy9j9Weh/Qv6Veo7sliAMdBxT3ZCDxqKy6ia21zcw9I6nmJJQj0VQNNRuheiM07IRAOqRmej9pmZCaBanpEGyFthZoD/+0NUP7HkgJhN+bdfDnOj6fse91F4T6nVC/Dep3QP122L0dGiu8Y+49bnuzd77gHkhJi3DcTNi9DSo/hLamfdfTrxiy86ByHTTXwp66nv19paR5yWa/BNRpOz2biEnIBb3ramvu9Dts2Xed+/1ew8+7Wi0gvQ/0LfJ+csOPfQdDVn7k5JWSCjmFkDPY+90dTigIlpIQibC7bRD17N8GsQNvjYiEtmRjNQAnq/1BAJprYPULsOlNqN7gJYaWHr6BHo3M/t4NLC3bSyTpfSC7wLuZBTIg1L7/zbO5xrup9hkA066BwvFQeAIMHAeZB0xEGWz3ShTNNbCn/ggDc7Cnwftscw201O573hx+3rDDS1LdTUaB9P2T3H6JL8tLNHv3pwQihOS866nfAbs+8h5dsPuXlJW3L6H0KfQSVMf11HrXuGe3l1Qy+x+cDNMyOaJSWErAO0/fwZA7xHvsWwTZAyAl+ksOdLeKqW+0A4lHSzZU0T87jbGFSXn5At63wQ2vw4p58OGfvG/k/YphwBgYOh3yR0LeSO+xb5H3/o5vtXu/zbfsK1nsLQmkhUsGoeD+JYrOn430zRjb/2aRMzj8rTtKAqmQne/9RFso6F1nJGZd3/SP9ZyNu7ySWEtt5PcE27zSYf12L6Hs3u4937V+X1LqW+Ql2az+XjIItnZKiLXQWOklpPY9Rxhfm1dKPbCPUEoqnH8PlEa3g2l3SxCXAgucc3Xh7f7Amc65F6MZnN+WbKxmRkk+KSm9v6goR8A5ry5+1e9g5dNedU5WHky/FqZ8CYomJ0T1QdxJCXhtFrE+Z99B3k+86khQnaoU67fD4BOjfurutkH8wDk3f++Gc67WzH4AJGyC2F7XzJbqJq45pcTvUCQWGqu8ksInC7yf+u1ePfKYT8N5d8HYc71v/CKxFkiDfsO8nxjrboKIVNl1tA3cvcKSDeH2Bw2QS0yhEGxbDuv+DB+/BttXAs6rHhh1Jow+C8ae41XjiCSp7t7kl5rZfwH34VWG3Qwsi1pUcWDJxir6ZqYyvkirxyWMthbY+Aas+xOse8VrILUADJ8Bn/q+lxSGTOn5em6RXqq7CeJm4P8Cz4S3/wrcEZWI4sSSDV77Q0DtD72bc15SWPoIfPw3aG2A9BwYczaMuwCO+3RsGmBFeqHu9mJqBG6Pcixxo2J3Cxt2NXLFjOF+hyJHq70VVj8Pb98HO1d53QInfR6OvwBGnqH2BJFu6G4vpleBzzvnasPbecDTzrlzohmcXzrGP4zU+g8HcQ4aKrwxAIE0rydFIM3vqPZpqvZKC+8+5FUhDTweLvpvmHR59wY5iUiH7lYxDdibHACcczVmlrBrUi/ZWEVORioThiR5+0NdOWxY6HX5rNnkjRau2QRtjfvek5bt1eEXnwIjZsHQ0uj2y4/EOdj8Frw/zxvI1t7stSdcch+MPltdUkWOUncTRMjMip1zWwDMrIQIs7smiiUbqpk+Io/UQPRHKvaoYDus/b1XrbJ7G8y6CU663hvM0x2tjbBp8b6unrvWeftTMyGvxBsQNmr2voFhe+phy9uw+W1Y+FPAeVMpDJkCQ6bB0GkwZCoUHBedUZ+1W+D938LKp7zElZ4DJ34eTr4BBk3o+fOJJJnuJojvA2+a2aLw9hnA3OiE5K+qhj2sr2jg0mlD/Q6l+1rqYPmTsOQ3UFcG+aOgYDT89fvw1n/DGd+GaV+OXO9es9nr6rnuZe9mH2z1EsKIU73PjD7Lq6bp6gY/cY732FwLZUtg82IoexdWPAnvPuC9lt43nDSmQvEsKJ7Z/YZh57zrq9/eaSTrNq/heeMbgPPaFM78Vxj/WW+aCRHpEea6mtDqwDd6VUpzgffxpvyucM69EcXYDqu0tNQtXbq0R4/58qrtfGPecp7/xilMH5HXo8fuUc55Q/2XPQbLn4DWehhxmldqGHuud0Pf9CYsuBO2vAX9hsPsf4HJX4Qdq/YlhZ2rveMNHO/16Bl9lncTP9b6+lDQm/Bt2wpvvMHW5d65gq3e64UneOcZcYpXRdXatG/Su86PdVu9KqMD5Y30rmXyFZA34thiFUkyZrbMOVd62Pd1J0GY2VeBW4BheAliJvC2c+6sQ34wyqKRIH74+w945r0y/vHDz5AWb1VMzTWwYVG4Cuh1qNvizckyYQ7MutH7hn4g57z3v34nbF3mlQ7aW7xRwsWzYNz5cPz5Xqkj2tpavGSxebFXLVW2xOt2eqD0vpBf4iWB/sX7JkeL1fxDIgmuuwmiu1VMtwAnAe845z5lZscDPzqWAOPVOxuqmD4iL36SQ+U6+OBF+PhV7wbvQpCR61WrnHYrjDvPu3F2xczr8z/6LPjoFa/UUDwTjjsH+sS4l1ZapldiGHGKtx1s97qgli+FzH772jayC9SwLBIHupsgWpxzLWaGmWU45z40s3FRjcwHtU2trNtZzwWTivwNpHojfPCC1yNn52rAYFgpnPEd70Y/dPqRdy0185LJuPOiEvJRCaR6pZ5IJR8R8V13E0R5eAbXF4FXzayGBFxydNXWOpyD6SU+tD20tcCyR70ZRLeGZzEZNgPOvRsmXKI5gUQk5ro7kvrS8NMfmtnrQD/glahF5ZOyaq8xtKQgxj1htq+EF74OlWu9qaQ//e8w4VKv/l1ExCdHPCOrc27R4d/VO5XVNJEWMAblxmheig7BAAAONklEQVTEbbAd3vw5LLrLmwriS7+DsZ+JzblFRA7Dl5ZYM7vFzFab2QdmdusBr33bzJyZDYh1XGXVTQzpnxWbCfp2rYdHPgOv/wROuBhufFvJQUTiSszXdDCzicDXgBlAK/CKmf3JObfezIYDnwa2xDougPKaZobnRbn7ZCgE7z0Er/7AG7j2uYdh0mXRPaeIyFHwowQxHq+7bJNzrh1YBOxt4/g58C/4NI1HeU0Tw/O7OS3F0Wipg6e/BC//C5ScBje+o+QgInHLj1XhVgN3mlkB0Aycj7cg0UXAVufcSvOhD3xTazu7GloZFq0SxM418MxVULvZ65l08tfV119E4lrME4Rzbq2Z3Q28CjQAK4F2vPmeDlsJb2ZzCc8DVVzcc718ttZ4PZiG5UWhBLH6BXjpm96C7Nf80Zv1VEQkzvnSSO2ce9g5N805dwZQDWwCRgIrzWwT3pQey83soM7/zrkHnXOlzrnSgQMH9lhMZTVNAAzP78ESRLAd/vJ9eO46GDwR5i5SchCRXsOPKibMrNA5V2FmxcAcYJZz7t5Or28CSp1zu2IV094xED1Wgmio9BLDpr/DSV+Dc/4DUtN75tgiIjHgS4IAng+3QbQBNznnanyKo0N5TROZaSkMzDnGpShDIXj/f+HVf4O2ZrjkfpjypZ4JUkQkhnxJEM650w/zekmMQulQVt3MsLxsjqmBfOcH8Md/hrJ3vBXWLvw5FB7fc0GKiMSQXyWIuFNW03T01UutjbDobm8lt4xcuPjXXqlBvZREpBdTgggrr2lmWvFRTNL3yevw+5u9ldymXu3No9Td1dJEROKYEgSwu6WNuua2Ix8k11QNz1wNuUVw3SvqoSQiCUUJAm8OJuDIB8m9+XNvRbTLn4DC8VGITETEP3GybJq/ysOD5I5oHqb6HfDuQ3Di5UoOIpKQlCDoXII4giqmN+6BUBuceXuUohIR8ZcSBF4JIicjlf7Z3VzGs2YzLHvMa5TOHxXV2ERE/KIEgTdIblheVvfHQCy6GyzFWyNaRCRBKUGwb5Bct1R+BCt/CzO+Bv2GRjcwEREfJX2CcM4d2ToQr98Jadlw2m3RDUxExGdJnyBqmtpobA12rwfT9pWw5kWY+Q3oE/MVUUVEYirpE8QR9WBacCdk9oNZ34xyVCIi/kv6BNExBuJw60BsWQLr/wKn3gpZ/WMQmYiIv5I+QexdKOiwJYgFP4Y+hd5SoSIiSUAJorqJ/tlp9M08xBiIrcu9hX9OuxXS+8QuOBERHyV9giivaT58A/XSh72eS1Ovik1QIiJxIOkTxGHXgWiugVXPw6TPew3UIiJJIqkTRCjkvBLEoRqo3/8ttDfDSdfHLjARkTiQ1AliV8MeWttDDO+qBOEcLH0Ehp0ERZNjG5yIiM+SOkHs68HURQli4xtQtR5KVXoQkeST3Amieu8YiC5KEEsfhqw8mHBpDKMSEYkPSZ0gyg9VgqjfAR/+CaZcCWmZMY5MRMR/SZ0gyqqbGZCTQWZa4OAXlz8BoXYo/UrsAxMRiQPJnSC6msU12A5LH4XRZ0HB6NgHJiISB5I6QXQ5SO6jV6B+mxqnRSSpJW2CCIYc22qbIw+SW/ow5A6FsefGPjARkTiRtAlie10z7SF38CC5qk/gkwUw7RoIpPoTnIhIHEjaBNExzfeBVUzLHgULwLQv+xCViEj8SNoEEXGhoLZmWPG/MP5CyC3yKTIRkfiQvAmiphkzGNK/U4LYtNibnG+qSg8iIkmbIMprmhicm0l6aqdfwc7V3uPQaf4EJSISR5I3QVRH6OJasRb6FkF2vj9BiYjEkaRNEGU1TQw7cJBcxQdQeII/AYmIxJmkTBCt7SF27G7Zfw6mYDtUfgSDlCBERMCnBGFmt5jZajP7wMxuDe/7f2b2oZn9w8zmm1n/aJ1/W20zzrH/OhDVGyC4BwonROu0IiK9SswThJlNBL4GzAAmAxea2XHAq8BE59yJwEfAv0Yrhr3rQOw3SK7iA++xcHy0Tisi0qv4UYIYD7zjnGtyzrUDi4BLnXN/DW8DvAMMi1YAewfJ7TcGYucasBQYOC5apxUR6VX8SBCrgTPMrMDMsoHzgeEHvOcrwMuRPmxmc81sqZktraysPKoAAinGmMIcBud2WuehYg3kj4a0LhYPEhFJMjGfbMg5t9bM7sarUmoAVgJ7Sw6Y2ffD2/O6+PyDwIMApaWl7mhiuLx0OJeXHpCTKtbA4ElHczgRkYTkSyO1c+5h59w059wZQDWwHsDMrgEuBK50zh3Vzf+otDZC9UZ1cRUR6cSX6UrNrNA5V2FmxcAcYJaZnQt8F5jtnGuKaUCVHwJOCUJEpBO/5rN+3swKgDbgJudcjZn9CsgAXjUz8Bqyb4hJNBVrvcdB6uIqIrKXLwnCOXd6hH1j/IgF8HowpWZBXolvIYiIxJukHEl9kIoPvO6tKQG/IxERiRtKEOCVIFS9JCKyHyWIxl3QWKEGahGRAyhBVKzxHjXFhojIfpQgdoYThKqYRET2owRRsQay8iFnkN+RiIjEFSWIinADtTf2QkREwpI7QYRC3iA5tT+IiBwkuRNE3RZobVAPJhGRCJI7QWiKDRGRLiV3gtgZXkVu4PH+xiEiEoeSO0FUrIF+xZCZ63ckIiJxJ8kTxFoYpPYHEZFIkjdBtLfCro/UQC0i0oXkTRBV6yHUrgZqEZEuJG+C2Kk5mEREDiV5E0TFGkhJhYLj/I5ERCQuJXeCGDAWUtP9jkREJC4lb4LYuUbVSyIih5CcCaJltzfNhnowiYh0KTkTROWH3qN6MImIdCk5E8TeKTZUghAR6VJyJoicQhh3AfQb7nckIiJxK9XvAHxx/AXej4iIdCk5SxAiInJYShAiIhKREoSIiESkBCEiIhEpQYiISERKECIiEpEShIiIRKQEISIiEZlzzu8YjpqZVQKbj/LjA4BdPRhOb5Gs1w3Je+267uTSnese4ZwbeLgD9eoEcSzMbKlzrtTvOGItWa8bkvfadd3JpSevW1VMIiISkRKEiIhElMwJ4kG/A/BJsl43JO+167qTS49dd9K2QYiIyKElcwlCREQOISkThJmda2brzOxjM7vd73iixcweMbMKM1vdaV++mb1qZuvDj3l+xhgNZjbczF43s7Vm9oGZ3RLen9DXbmaZZvauma0MX/ePwvtHmtmS8HU/Y2bpfscaDWYWMLMVZvbH8HbCX7eZbTKzVWb2vpktDe/rsb/zpEsQZhYA7gPOA04Avmhmibr26GPAuQfsux14zTl3HPBaeDvRtAP/xzk3HpgJ3BT+f5zo174HOMs5NxmYApxrZjOBu4Gfh6+7Brjexxij6RZgbaftZLnuTznnpnTq2tpjf+dJlyCAGcDHzrkNzrlW4GngYp9jigrn3BtA9QG7LwYeDz9/HLgkpkHFgHNuu3Nuefh5Pd5NYygJfu3O0xDeTAv/OOAs4Lnw/oS7bgAzGwZcAPxPeNtIguvuQo/9nSdjghgKlHXaLg/vSxaDnHPbwbuRAoU+xxNVZlYCTAWWkATXHq5meR+oAF4FPgFqnXPt4bck6t/7L4B/AULh7QKS47od8FczW2Zmc8P7euzvPBnXpLYI+9SVKwGZWQ7wPHCrc26396UysTnngsAUM+sPzAfGR3pbbKOKLjO7EKhwzi0zszP37o7w1oS67rBTnXPbzKwQeNXMPuzJgydjCaIcGN5pexiwzadY/LDTzIoAwo8VPscTFWaWhpcc5jnnXgjvToprB3DO1QIL8dpg+pvZ3i+Difj3fipwkZltwqsyPguvRJHo141zblv4sQLvC8EMevDvPBkTxHvAceEeDunAFcDvfY4pln4PXBN+fg3wko+xREW4/vlhYK1z7r86vZTQ125mA8MlB8wsC/gnvPaX14HLwm9LuOt2zv2rc26Yc64E79/zAufclST4dZtZHzPru/c58BlgNT34d56UA+XM7Hy8bxgB4BHn3J0+hxQVZvZb4Ey82R13Aj8AXgSeBYqBLcDnnXMHNmT3amZ2GvB3YBX76qS/h9cOkbDXbmYn4jVKBvC+/D3rnPt3MxuF9806H1gBXOWc2+NfpNETrmL6tnPuwkS/7vD1zQ9vpgJPOefuNLMCeujvPCkThIiIHF4yVjGJiEg3KEGIiEhEShAiIhKREoSIiESkBCEiIhEpQYjEkJmduXe2UZF4pwQhIiIRKUGIRGBmV4XXVnjfzB4IT4LXYGb/aWbLzew1MxsYfu8UM3vHzP5hZvP3zr9vZmPM7G/h9RmWm9no8OFzzOw5M/vQzOaFR35jZneZ2Zrwce7x6dJFOihBiBzAzMYDX8CbCG0KEASuBPoAy51z04BFeCPTAZ4AvuucOxFv9Pbe/fOA+8LrM5wCbA/vnwrcirceySjgVDPLBy4FJoSP85PoXqXI4SlBiBzsbGA68F546uyz8W7kIeCZ8Hv+FzjNzPoB/Z1zi8L7HwfOCM+RM9Q5Nx/AOdfinGsKv+dd51y5cy4EvA+UALuBFuB/zGwOsPe9Ir5RghA5mAGPh1fpmuKcG+ec+2GE9x1qnppDzS3eeT6gIJAaXrdgBt4MtJcArxxhzCI9TglC5GCvAZeF59jfu8bvCLx/L3tnB/0S8KZzrg6oMbPTw/uvBhY553YD5WZ2SfgYGWaW3dUJw2tX9HPO/Rmv+mlKNC5M5Egk44JBIofknFtjZnfgrdSVArQBNwGNwAQzWwbU4bVTgDel8m/CCWADcF14/9XAA2b27+FjfP4Qp+0LvGRmmXilj9t6+LJEjphmcxXpJjNrcM7l+B2HSKyoiklERCJSCUJERCJSCUJERCJSghARkYiUIEREJCIlCBERiUgJQkREIlKCEBGRiP4/VlqOhOOErpMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a225e2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(0,50))\n",
    "\n",
    "plt.plot(epochs,accuracy_train)\n",
    "plt.plot(epochs,accuracy_val)\n",
    "plt.legend(('train_acc','val_acc'))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nn_input_dim = 784\n",
    "nn_output_dim = 10\n",
    "epsilon = 0.01 # learning rate for gradient descent\n",
    "reg_lambda = 0.01 # regularization strength\n",
    "num_examples = len(xdata_train)\n",
    "\n",
    "def build_model(nn_hdim, num_passes=50, print_loss=False):\n",
    "     \n",
    "    # Initialize the parameters to random values. We need to learn these.\n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((1, nn_output_dim))\n",
    " \n",
    "    # This is what we return at the end\n",
    "    model = {}\n",
    "     \n",
    "    # Gradient descent. For each batch...\n",
    "    for i in range(0, num_passes):\n",
    " \n",
    "        # Forward propagation\n",
    "        z1 = xdata_train.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_scores = np.exp(z2)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    " \n",
    "        # Backpropagation\n",
    "        delta3 = probs - ydata_train\n",
    "#         print(delta3)\n",
    "#         delta3[range(num_examples), ydata_train] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(xdata_train.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    " \n",
    "        # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    " \n",
    "        # Gradient descent parameter update\n",
    "        W1 += -epsilon * dW1\n",
    "        b1 += -epsilon * db1\n",
    "        W2 += -epsilon * dW2\n",
    "        b2 += -epsilon * db2\n",
    "         \n",
    "        # Assign new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "         \n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        if print_loss and i % 1000 == 0:\n",
    "            print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model)))\n",
    "     \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
